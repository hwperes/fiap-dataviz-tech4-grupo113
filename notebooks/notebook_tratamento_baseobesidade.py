# -*- coding: utf-8 -*-
"""Cópia de Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B1YDeowZPqSe8b6yXR3HJ1fFjRyyEqT5
"""

!pip install -q scikit-learn pandas numpy matplotlib seaborn joblib

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

import joblib

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("Obesity.csv")

df.head()

df.info()

df.describe()

plt.figure(figsize=(10,5))
sns.countplot(data=df, x="Obesity")
plt.xticks(rotation=45)
plt.title("Distribuição dos Níveis de Obesidade")
plt.show()

X = df.drop("Obesity", axis=1)
y = df["Obesity"]

cat_features = X.select_dtypes(include="object").columns
num_features = X.select_dtypes(exclude="object").columns

print("Variáveis Categóricas:", list(cat_features))
print("Variáveis Numéricas:", list(num_features))

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features)
    ]
)

model = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    class_weight="balanced"
)

pipeline = Pipeline(
    steps=[
        ("preprocessing", preprocessor),
        ("model", model)
    ]
)

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Acurácia do modelo: {accuracy:.2%}")
y_pred = pipeline.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Acurácia do modelo: {accuracy:.2%}")

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.title("Matriz de Confusão")
plt.show()

feature_names = (
    pipeline.named_steps["preprocessing"]
    .transformers_[1][1]
    .get_feature_names_out(cat_features)
)

all_features = np.concatenate([num_features, feature_names])

importances = pipeline.named_steps["model"].feature_importances_

feat_imp = pd.DataFrame({
    "Feature": all_features,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

feat_imp.head(10)

plt.figure(figsize=(10,6))
sns.barplot(
    data=feat_imp.head(10),
    x="Importance",
    y="Feature"
)
plt.title("Top 10 Features Mais Importantes")
plt.show()

joblib.dump(pipeline, "model_obesity.pkl")

files.download("model_obesity.pkl")

# Previsão para todo o dataset
df["Obesity_pred"] = pipeline.predict(X)

# Probabilidade máxima da previsão
probas = pipeline.predict_proba(X)
df["Probabilidade"] = probas.max(axis=1)

# Flag de erro
df["Erro_Predicao"] = np.where(
    df["Obesity"] == df["Obesity_pred"], "Não", "Sim"
)

df.head()

df["IMC"] = df["Weight"] / (df["Height"] ** 2)

df["Faixa_Etaria"] = pd.cut(
    df["Age"],
    bins=[0, 18, 30, 45, 60, 100],
    labels=["Adolescente", "Jovem Adulto", "Adulto", "Meia Idade", "Idoso"]
)

df["Nivel_Risco"] = df["Obesity_pred"].apply(
    lambda x: "Alto" if "Obesity" in x else "Moderado"
)

performance = (
    df.groupby("Obesity")
    .agg(
        Total=("Obesity", "count"),
        Acertos=("Erro_Predicao", lambda x: (x == "Não").sum())
    )
    .reset_index()
)

performance["Acuracia"] = performance["Acertos"] / performance["Total"]

performance

colunas_pt = {
    "Gender": "Genero",
    "Age": "Idade",
    "Height": "Altura_m",
    "Weight": "Peso_kg",
    "family_history": "Historico_Familiar_Obesidade",
    "FAVC": "Consumo_Alimentos_Caloricos",
    "FCVC": "Consumo_Vegetais",
    "NCP": "Refeicoes_Diarias",
    "CAEC": "Lanches_Entre_Refeicoes",
    "SMOKE": "Fumante",
    "CH2O": "Consumo_Agua",
    "SCC": "Monitora_Calorias",
    "FAF": "Atividade_Fisica",
    "TUE": "Tempo_Dispositivos",
    "CALC": "Consumo_Alcool",
    "MTRANS": "Meio_Transporte",
    "Obesity": "Nivel_Obesidade",
    "Obesity_pred": "Nivel_Obesidade_Previsto",
    "Probabilidade": "Probabilidade_Modelo",
    "Erro_Predicao": "Erro_Predicao"
}

df_pt = df.rename(columns=colunas_pt)

df_pt["Genero"] = df_pt["Genero"].replace({
    "Male": "Masculino",
    "Female": "Feminino"
})

sim_nao = {
    "yes": "Sim",
    "no": "Não"
}

colunas_sim_nao = [
    "Historico_Familiar_Obesidade",
    "Consumo_Alimentos_Caloricos",
    "Fumante",
    "Monitora_Calorias"
]

for col in colunas_sim_nao:
    df_pt[col] = df_pt[col].replace(sim_nao)

traducao_obesidade = {
    "Insufficient_Weight": "Abaixo do Peso",
    "Normal_Weight": "Peso Normal",
    "Overweight_Level_I": "Sobrepeso I",
    "Overweight_Level_II": "Sobrepeso II",
    "Obesity_Type_I": "Obesidade Grau I",
    "Obesity_Type_II": "Obesidade Grau II",
    "Obesity_Type_III": "Obesidade Grau III"
}

df_pt["Nivel_Obesidade"] = df_pt["Nivel_Obesidade"].replace(traducao_obesidade)
df_pt["Nivel_Obesidade_Previsto"] = df_pt["Nivel_Obesidade_Previsto"].replace(traducao_obesidade)

atividade_fisica = {
    0: "Nenhuma",
    1: "1–2x por semana",
    2: "3–4x por semana",
    3: "5x ou mais"
}

df_pt["Atividade_Fisica"] = df_pt["Atividade_Fisica"].round().map(atividade_fisica)

df_pt.head()
df_pt.info()

df_pt.head()

df_pt.to_csv("obesidade_analitico_ptbr.csv", index=False)

from google.colab import files
files.download("obesidade_analitico_ptbr.csv")

from google.colab import files

# Salvar o pipeline treinado
joblib.dump(pipeline, "model_obesity.joblib")

print("Modelo salvo com sucesso!")

# Download para sua máquina
files.download("model_obesity.joblib")